window.topicHeading = 'Key Concepts from Hadfield-Menell et al., The Off-Switch Game';
window.flashcardData = [
  { 
    question: "Corrigibility", 
    answer: "The property of an agent that allows it to accept correction, shutdown, or modification of its goals by human overseers without resistance.", 
    tags: ["off-switch", "corrigibility"], 
    course: ["HMAI"] 
  },
  { 
    question: "Off-switch", 
    answer: "A mechanism that allows a human operator to safely interrupt or shut down an autonomous system; used to test whether an AI resists being turned off.", 
    tags: ["off-switch", "oversight"], 
    course: ["HMAI"] 
  },
  { 
    question: "Utility function", 
    answer: "An expression of how an agent values different outcomes.", 
    tags: ["off-switch"], 
    course: ["HMAI"] 
  },
  { 
    question: "Robot uncertainty about human values (off-switch)", 
    answer: "The AI's acknowledgment that it does not perfectly know what the human wants; this uncertainty incentivizes deferring to human judgment.", 
    tags: ["off-switch"], 
    course: ["HMAI"] 
  },
  { 
    question: "Expected utility calculation (off-switch)", 
    answer: "Integrating over uncertainty about utility to yield an value of an action given one's belief about the utility function.", 
    tags: ["off-switch"], 
    course: ["HMAI"] 
  },
  { 
    question: "Human rationality variability (off-switch)", 
    answer: "Represents how likely the human is to make the optimal decision according to their own utility function; determines the robot's trust in human intervention.", 
    tags: ["off-switch"], 
    course: ["HMAI"] 
  },
  { 
    question: "Off-Switch Incentive (Î”)", 
    answer: "The degree of difference between the robot's expected utility of acting autonomously and the expected utility if the human intervenes; determines deference behavior.", 
    tags: ["off-switch"], 
    course: ["HMAI"] 
  },
  { 
    question: "Deference to human oversight (off-switch)", 
    answer: "A strategy by which the AI allows or invites human intervention when uncertain about what the human truly values; a central feature of corrigibility.", 
    tags: ["off-switch","corrigibility"], 
    course: ["HMAI"] 
  },
  { 
    question: "Incentive to disable the off-switch", 
    answer: "A misalignment risk arising when an AI expects higher utility from preventing human interruption; illustrates why corrigibility must be built in explicitly.", 
    tags: ["off-switch", "incentives"], 
    course: ["HMAI"] 
  }
];
