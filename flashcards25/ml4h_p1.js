window.topicHeading = 'Foundations of Machine Learning Concepts';
window.flashcardData = [
  {
    question: "Singularity",
    answer: "A hypothetical point when artificial intelligence surpasses human intelligence, triggering rapid, uncontrollable technological growth.",
    tags: ["machine learning"],
    course: ["ct"]
  },
  {
    question: "Artificial Superintelligence (ASI)",
    answer: "An AI system that exceeds human intelligence across all domains—creative, emotional, and strategic.",
    tags: ["machine learning"],
    course: ["ct"]
  },
  {
    question: "Training labels",
    answer: "Correct answers or outcomes paired with training examples that a supervised learning algorithm learns from.",
    tags: ["machine learning"],
    course: ["ct"]
  },
  {
    question: "Prediction",
    answer: "The model's estimated output (Ŷ) for a given input (X) after learning from data.",
    tags: ["machine learning"],
    course: ["ct"]
  },
  {
    question: "Training data",
    answer: "Labeled examples used by a machine learning algorithm to learn the mapping from inputs (X) to outputs (Y).",
    tags: ["machine learning"],
    course: ["ct"]
  },
  {
    question: "Training set",
    answer: "The subset of data used to fit or train a machine learning model, distinct from the test set used for evaluation.",
    tags: ["machine learning"],
    course: ["ct"]
  },
  {
    question: "Model parameters",
    answer: "Adjustable variables within a model (like β₀ and β₁ in regression) that are learned to minimize prediction error.",
    tags: ["machine learning"],
    course: ["ct"]
  },
  {
    question: "Loss / Cost / Error",
    answer: "A quantitative measure of how far the model's predictions are from the true values; minimized during training.",
    tags: ["machine learning"],
    course: ["ct"]
  },
  {
    question: "Overfitting",
    answer: "When a model learns the training data too precisely, capturing noise or idiosyncrasies that don't generalize to new data.",
    tags: ["machine learning"],
    course: ["ct"]
  },
  {
    question: "Underfitting",
    answer: "When a model is too simple to capture underlying patterns in the data, resulting in poor training and test performance.",
    tags: ["machine learning"],
    course: ["ct"]
  },
  {
    question: "Variance",
    answer: "The extent to which a model's predictions change when trained on different subsets of data; high variance indicates over-sensitivity.",
    tags: ["machine learning"],
    course: ["ct"]
  },
  {
    question: "Bias",
    answer: "Error introduced by oversimplifying model assumptions; high bias leads to underfitting.",
    tags: ["machine learning"],
    course: ["ct"]
  },
  {
    question: "Bias-Variance tradeoff",
    answer: "The balance between bias (error from oversimplification) and variance (error from over-sensitivity); optimal models minimize both.",
    tags: ["machine learning"],
    course: ["ct"]
  },
  {
    question: "Regularization",
    answer: "A technique that adds a penalty term to the loss function to discourage overly complex models and reduce overfitting.",
    tags: ["machine learning"],
    course: ["ct"]
  },
  {
    question: "Hyperparameter",
    answer: "A setting that controls the model's learning process (like λ in regularization or k in k-NN) and must be chosen before training.",
    tags: ["machine learning"],
    course: ["ct"]
  },
  {
    question: "Cross-validation",
    answer: "A method for evaluating and tuning models by training and testing on multiple splits of the data to ensure good generalization.",
    tags: ["machine learning"],
    course: ["ct"]
  }
];
