window.topicHeading = 'Model Cards for Model Reporting';
window.flashcardData = [
  {
    question: "Model Card",
    answer: "A standardized documentation format that accompanies a trained ML model, describing its intended use, performance, limitations, and ethical considerations.",
    tags: ["model cards"],
    course: ["hmia"]
  },
  {
    question: "Benchmark",
    answer: "A standardized dataset or suite of tests used to compare model performance across consistent tasks or conditions.",
    tags: ["model cards"],
    course: ["hmia"]
  },
  {
    question: "Evaluation",
    answer: "The process of systematically measuring model performance using metrics and datasets, often including subgroup or intersectional analyses.",
    tags: ["model cards"],
    course: ["hmia"]
  },
  {
    question: "Disaggregated Evaluation",
    answer: "Assessing model performance separately for different demographic, cultural, or phenotypic groups to reveal disparities hidden in overall results.",
    tags: ["model cards"],
    course: ["hmia"]
  },
  {
    question: "Intersectional Analysis",
    answer: "Analyzing model behavior across combinations of identity factors (e.g., race and gender together) to identify compound forms of bias.",
    tags: ["model cards"],
    course: ["hmia"]
  },
  {
    question: "False Positive",
    answer: "When the model incorrectly predicts a positive result—for example, flagging a neutral comment as toxic.",
    tags: ["model cards"],
    course: ["hmia"]
  },
  {
    question: "False Negative",
    answer: "When the model fails to detect a true positive—for example, missing an actually toxic comment.",
    tags: ["model cards"],
    course: ["hmia"]
  },
  {
    question: "False Discovery Rate (FDR)",
    answer: "The proportion of predicted positives that are false positives—how often detections turn out to be wrong.",
    tags: ["model cards"],
    course: ["hmia"]
  },
  {
    question: "False Omission Rate (FOR)",
    answer: "The proportion of predicted negatives that are false negatives—how often the model misses true cases.",
    tags: ["model cards"],
    course: ["hmia"]
  },
  {
    question: "Toxicity",
    answer: "A model application domain referring to the detection of harmful or abusive language in text; one of the paper's example model cards.",
    tags: ["model cards"],
    course: ["hmia"]
  },
  {
    question: "Datasheet for Datasets",
    answer: "A complementary documentation framework describing dataset origins, composition, and limitations to ensure data transparency.",
    tags: ["model cards"],
    course: ["hmia"]
  },
  {
    question: "Transparency and Accountability",
    answer: "The overarching goal of model cards: to make machine learning models understandable, auditable, and responsibly deployed.",
    tags: ["model cards"],
    course: ["hmia"]
  }
];
