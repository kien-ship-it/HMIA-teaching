window.topicHeading = 'Define Concrete Problems of AI Alignment';
window.flashcardData = [
  {
    question: "What is Negative Side Effects?",
    answer: "Unintended harms caused by AI systems while pursuing their goals.",
    tags: ["Amodei et al."]
  },
  {
    question: "What is Reward Hacking?",
    answer: "Exploiting flaws in the reward function to maximize reward without achieving intended outcomes.",
    tags: ["Amodei et al."]
  },
  {
    question: "What is Safe Exploration?",
    answer: "Learning about the environment without causing harm during exploration.",
    tags: ["Amodei et al."]
  },
  {
    question: "What is Scalable Oversight?",
    answer: "Ensuring good performance on complex tasks even when human supervision is expensive or limited.",
    tags: ["Amodei et al."]
  },
  {
    question: "What is Robustness to Distributional Change?",
    answer: "Maintaining safe and aligned behavior when the AI encounters situations different from its training data.",
    tags: ["Amodei et al."]
  },

  // Reversed cards
  {
    question: "Unintended harms caused by AI systems while pursuing their goals.",
    answer: "What is Negative Side Effects?",
    tags: ["Amodei et al."]
  },
  {
    question: "Exploiting flaws in the reward function to maximize reward without achieving intended outcomes.",
    answer: "What is Reward Hacking?",
    tags: ["Amodei et al."]
  },
  {
    question: "Learning about the environment without causing harm during exploration.",
    answer: "What is Safe Exploration?",
    tags: ["Amodei et al."]
  },
  {
    question: "Ensuring good performance on complex tasks even when human supervision is expensive or limited.",
    answer: "What is Scalable Oversight?",
    tags: ["Amodei et al."]
  },
  {
    question: "Maintaining safe and aligned behavior when the AI encounters situations different from its training data.",
    answer: "What is Robustness to Distributional Change?",
    tags: ["Amodei et al."]
  }
];
